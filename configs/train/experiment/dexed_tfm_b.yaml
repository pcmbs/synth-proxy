# @package _global_

defaults:
  - override /train_dataset: dexed_mn04_v1
  - override /val_dataset: dexed_mn04_v1
  - override /m_preset: tfm

task_name: dexed_tfm_b

########## hyperparameters 

m_preset: # 4_824_768 parameters
  cfg:
    num_blocks: 6
    hidden_features: 256
    num_heads: 8
    mlp_factor: 4
    pooling_type: cls

solver:
  lr: 1e-3
  optimizer:
    betas:
      - 0.910 # 0.890
      - 0.987
    eps: 2e-8 # 5e-10

  scheduler:
    _target_: utils.lr_schedulers.wcrc_scheduler_builder 
    min_lr: 2e-6
    num_warmup_steps: 7500
    warmup_factor: 1.0
    num_decay_steps: 392_500 # warmup+cosine corresponds to 10 epochs at bs=256
    num_restart_steps: 800_000 # 20 epochs
    restart_factor: 1.0 # full restart

########## training setup
train_dataset:
  loader:
    batch_size: 256

trainer:
  # kwargs for lightning trainer
  max_epochs: 30
  
  # set True to to ensure deterministic results
  # improve reproducibility over setting seeds alone (can slightly slow training)
  deterministic: True
