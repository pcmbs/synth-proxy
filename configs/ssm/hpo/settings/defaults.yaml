# @package _global_

######################################
############ Data Configs ############
######################################

######################################
############ Data Configs ############
######################################
dataset:
  path_to_dataset: ${paths.root_dir}/data/datasets/eval/${synth}_${dataset_name}
  split: train
  # has_mel: null # passed in main config

num_workers: 0

# the follow value are required to have a 0.8-0.1-0.1 train-val-test split
train_val_split: 
  - 0.89
  - 0.11

########################################
############ Optuna configs ############
########################################
# in which direction the objective should be optimized (minimize or maximize)
direction: minimize

# metric to optimize (for optuna lightning callback)
metric_to_optimize: val/loss

sampler:
  # number of QMC startup trials to run before the TPE algorithm
  num_startup_trials: ${num_startup_trials}

  name_startup_sampler: qmc
  name: tpe

  cfg:
    _target_: optuna.samplers.TPESampler
    # The random sampling is used instead of the TPE algorithm until the given number of trials finish in the same study.
    n_startup_trials: 0
    multivariate: true
    group: true
    seed: ${seed}
    warn_independent_sampling: false

  cfg_startup:
    _target_: optuna.samplers.QMCSampler
    # can be "sobol" or "halton"
    # -> if using sobol, it is recommended that the number of trials should be set as power of two.
    qmc_type: sobol
    # Scrambling is capable of producing better Sobol sequences.
    scramble: true
    # seed for the RNG
    seed: ${seed}
    warn_independent_sampling: false

pruner:
  cfg:
    _target_: optuna.pruners.NopPruner

  name: nop


#####################################
############ Synth proxy ############
#####################################
synth_proxy:
  _target_: models.preset.tfm
  pe_type: absolute
  hidden_features: 256
  num_blocks: 6
  num_heads: 8
  mlp_factor: 4.0
  pooling_type: cls
  last_activation: ReLU
  pe_dropout_p: 0.0
  block_activation: relu
  block_dropout_p: 0.0


###################################
############ Artifacts ############
###################################
# name of the optuna study
study_name: ssm_${synth}_${dataset_name}_bs${batch_size}_${tag}

######################################
############ Hydra configs ###########
######################################
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  output_dir: ${hydra:runtime.output_dir}

hydra:
  run:
    dir: ${paths.root_dir}/logs/optuna/${study_name}
  sweep:
    dir:  ${paths.root_dir}/logs/optuna/${study_name}
    subdir: ${hydra.job.num}

  job: 
    chdir: True

  job_logging:
    handlers:
      file:
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
    formatters:
      simple:
        format: '%(message)s'


#######################################
############ wandb configs ############
#######################################
wandb:
  _target_: lightning.pytorch.loggers.wandb.WandbLogger
  # name: "" # name of the run (generated by wandb and can be changed afterward)
  save_dir: ${paths.output_dir}
  offline: False
  id: null # pass correct id to resume experiment!
  anonymous: null # enable anonymous logging
  project: hpo_${study_name}
  log_model: False # upload lightning ckpts
  job_type: hpo