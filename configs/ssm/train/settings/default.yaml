# @package _global_

######################################
############ Data Configs ############
######################################
dataset:
  path_to_dataset: ${paths.root_dir}/data/datasets/eval/${synth}_${dataset_name}
  split: train
  has_mel: true

num_workers: 0

# the follow value are required to have a 0.8-0.1-0.1 train-val-test split
train_val_split: 
  - 0.89
  - 0.11

# random seed for reproducibility
seed: 42

#############################################
############ Lightning Callbacks ############
#############################################
callbacks:
  
  ckpt_last:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints # directory to save the model file
    filename: last
    auto_insert_metric_name: False # when True, the checkpoints filenames will contain the metric name
    every_n_epochs: 50 # number of epochs between checkpoints
    save_on_train_epoch_end: True # run checkpointing at the end of the training epoch
  
  ckpt_loss:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints # directory to save the model file
    filename: ${task_name}_e{epoch}_loss{val/loss/total:.4f}
    auto_insert_metric_name: False # when True, the checkpoints filenames will contain the metric name
    monitor: "val/loss/total" # name of the logged metric which determines when model is improving
    mode: min # max/min means higher/lower metric value is better
    save_top_k: 5 # save k best models (determined by above metric)
    every_n_epochs: 1 # number of epochs between checkpoints
    save_on_train_epoch_end: False # run checkpointing at the end of the validation epoch
  
  learning_rate_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step # set to 'epoch' or 'step' to log lr of all optimizers at the same interval
    log_momentum: False # option to also log the momentum values of the optimizer, if the optimizer has the momentum or betas attribute
  
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar


#####################################
############ Synth proxy ############
#####################################
synth_proxy:
  _target_: models.preset.tfm
  pe_type: absolute
  hidden_features: 256
  num_blocks: 6
  num_heads: 8
  mlp_factor: 4.0
  pooling_type: cls
  last_activation: ReLU
  pe_dropout_p: 0.0
  block_activation: relu
  block_dropout_p: 0.0


###################################
############ Artifacts ############
###################################
task_name: ${synth}_ssm_${dataset_name}_${tag}

######################################
############ Hydra configs ###########
######################################
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  output_dir: ${hydra:runtime.output_dir}

hydra:
  run:
    dir: ${paths.root_dir}/logs/ssm/${task_name}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  sweep:
    dir:  ${paths.root_dir}/logs/ssm/multirun_${now:%Y-%m-%d}_${now:%H-%M-%S}
    subdir: ${hydra.job.num}_${task_name}

  job: 
    chdir: True

  job_logging:
    handlers:
      file:
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
    formatters:
      simple:
        format: '%(message)s'


#######################################
############ wandb configs ############
#######################################
wandb:
  # name: "" # name of the run (generated by wandb and can be changed afterward)
  save_dir: ${paths.output_dir}
  offline: False
  id: ${run_id} # pass correct id to resume experiment!
  anonymous: null # enable anonymous logging
  project: "synth_proxy_ssm"
  log_model: False # upload lightning ckpts
  job_type: train
  # if id is set with init(id="run_id") or WANDB_RUN_ID="run_id" and it is identical to a previous run
  # wandb will automatically resume the run with that id. Otherwise, wandb will start a new run.
  resume: allow