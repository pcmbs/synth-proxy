# @package _global_

# synthesizer to use
synth: diva

# path to the checkpoint to load for the synth proxy
path_to_ckpt: ${paths.root_dir}/checkpoints/diva_tfm_mn20_hc_v1_ft_e50_loss0.0379.ckpt

optimizer:
  optimizer_kwargs:
    lr: 3e-4
    betas:
      - 0.91
      - 0.98
    eps: 1e-7
    weight_decay: 0.3
  num_warmup_steps: 1080

label_smoothing: 0.01

# diva: len(train_dataset)= 7721 if [0.8, 0.1, 0.1] split is used
# total_num_steps = num_epochs * dataset_size // batch_size
total_num_steps: ${total_num_steps:${trainer.max_epochs},7721,${batch_size}}

# step number at which the linear schedule start for both loss
# while warmp is the number of steps for which the linear schedule is active

# to follow SSSSM-DDSP paper, the start ratio should be 0.125 (warmp around 0.375)
# here we train for 600 epochs and start half-way through
start: ${start:${total_num_steps},${start_ratio}}
warm: ${warm:${total_num_steps},0.33}