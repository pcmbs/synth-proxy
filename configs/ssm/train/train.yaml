# @package _global_

defaults:
  - _self_
  - synth: diva
  - settings: defaults
  - loss_sch: ???


######################################
############ Main Configs ############
######################################

# tag to identify the run
tag: ???

#dataset to use for finetuning
dataset_name: mn20_hc_v1

# step number at which the linear schedule start for both loss
# total_num_steps = num_epochs * dataset_size // batch_size
# to follow SSSSM-DDSP paper, should be num_steps // 8
start: 0

# how long should the linear schedule last
# to follow SSSSM-DDSP paper, should be num_steps // 2 - start
warm: 0

# batch size for the train and val dataloaders
batch_size: 64

# number of epochs
trainer:
  max_epochs: 250
  log_every_n_steps: 50
  deterministic: True
  accelerator: gpu
  devices: 1
  default_root_dir: ${paths.output_dir}

# activate SLURMEnvironment auto requeue 
slurm:
  auto_requeue: True

# for resuming tranining
ckpt_path: null

##########################################
############ Lightning Module ############
##########################################
# see synth configs for optimizer kwargs
optimizer:
  scheduler_kwargs:
    factor: 0.5
    patience: 10

wandb_watch_args:
  log: null
  log_freq: 100 